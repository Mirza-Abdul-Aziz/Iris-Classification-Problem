{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.9 64-bit ('mirza': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "07f924eb4d022e91b8bf4ce0e98b46054cc0d26883ba7a1448b3ba88fd5baa21"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "source": [
    "# Loading the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nLoaded Data :\n------------------------------------\n  CLASS                                                SMS\n0   ham   said kiss, kiss, i can't do the sound effects...\n1   ham      &lt;#&gt; ISH MINUTES WAS 5 MINUTES AGO. WTF.\n2  spam  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...\n3  spam  * FREE* POLYPHONIC RINGTONE Text SUPER to 8713...\n4  spam  **FREE MESSAGE**Thanks for using the Auction S...\n"
     ]
    }
   ],
   "source": [
    "#Load Spam Data and review content\n",
    "spam_data = pd.read_csv(\"Spam-Classification.csv\")\n",
    "\n",
    "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
    "print(spam_data.head())"
   ]
  },
  {
   "source": [
    "# Separate input features and output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate feature and target data\n",
    "spam_classes_raw = spam_data[\"CLASS\"]\n",
    "spam_messages = spam_data[\"SMS\"]"
   ]
  },
  {
   "source": [
    "# Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mirza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mirza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mirza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mirza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Installing the necessary text pre-processing libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom tokenizer to remove stop words and to use the lemmitization\n",
    "def customtokenize(str):\n",
    "    # Converting the string into tokens\n",
    "    tokens = nltk.word_tokenize(str)\n",
    "    # Filtering of stop words\n",
    "    nostop = list(filter(lambda token: token not in stopwords.words('english'), tokens))\n",
    "    #Lemmatization\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in nostop]\n",
    "    return lemmatized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a TF-IDF vectorizer model which is an NLP technique\n",
    "vectorizer = TfidfVectorizer(tokenizer=customtokenize)\n",
    "#Converting input into TF-IDF\n",
    "tfidf=vectorizer.fit_transform(spam_messages)\n",
    "#Converting the TF-IDF vectors into array which is the preferred input for kears\n",
    "tfidf_array = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding of the output to convert it to numeric representation\n",
    "label_encoder = LabelEncoder()\n",
    "spam_classes = label_encoder.fit_transform(spam_classes_raw)\n",
    "\n",
    "# Converting the output to one hot encoding vector for keras\n",
    "spam_classes = tf.keras.utils.to_categorical(spam_classes, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(tfidf_array, spam_classes, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TF-IDF Matrix Shape :  (1500, 4569)\nOne-hot Encoding Shape :  (1500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Matrix Shape : \", tfidf.shape)\n",
    "print(\"One-hot Encoding Shape : \", spam_classes.shape)"
   ]
  },
  {
   "source": [
    "# Training and Evaluating the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden-Layer-1 (Dense)      (None, 32)                146240    \n",
      "                                                                 \n",
      " Hidden-Layer-2 (Dense)      (None, 32)                1056      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,362\n",
      "Trainable params: 147,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NB_CLASSES=2 #No of outputs\n",
    "N_HIDDEN=32 # No of nodes in the hidden layer\n",
    "\n",
    "#Initialization of the keras Sequential Model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Add the first hidden layer in the model\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        N_HIDDEN,\n",
    "        input_shape=(X_train.shape[1],), #No. of inputs\n",
    "        name=\"Hidden-Layer-1\", #Hidden Layer name\n",
    "        activation='relu' # activation function\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        N_HIDDEN,\n",
    "        name=\"Hidden-Layer-2\",\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        NB_CLASSES,\n",
    "        name=\"Output-Layer\",\n",
    "        activation=\"softmax\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}